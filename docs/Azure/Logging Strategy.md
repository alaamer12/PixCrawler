# Logging Strategy

## Table of Contents

1. [Logging Strategy Overview](about:blank#logging-strategy)
2. [Structured Logging Explained](about:blank#structured-logging)
3. [JSON Logs in Production](about:blank#json-logs)
4. [Production Logging Workflow](about:blank#production-workflow)
5. [Azure Monitor Deep Dive](about:blank#azure-monitor)
6. [Storage Strategy](about:blank#storage-strategy)
7. [Query Language & Tools](about:blank#query-tools)
8. [Configuration Split](about:blank#configuration-split)
9. [Implementation Changes](about:blank#implementation)
10. [Deployment Checklist](about:blank#deployment)

---

## Logging Strategy Overview

### Core Principle: Task-Level Logging

**Recommended Approach:** Log per-task with rich context

```python
from logging_config import get_logger
from celery import Task
@celery_app.task(bind=True)
def process_chunk(self: Task, chunk_id: str):
    # Bind task-specific context    logger = get_logger().bind(
        task_id=self.request.id,
        task_name=self.name,
        chunk_id=chunk_id,
        worker=self.request.hostname
    )
    logger.info("Starting chunk processing")
    logger.debug(f"Downloading {500} images")
    # ... processing ...    logger.info("Chunk completed", images_processed=450)
```

**Output:**

```
2025-10-30 22:33:55 | INFO | process_chunk | task_id=abc-123 chunk_id=chunk_001 worker=worker1 - Starting chunk processing
2025-10-30 22:34:10 | INFO | process_chunk | task_id=abc-123 chunk_id=chunk_001 worker=worker1 - Chunk completed
```

**Benefits:**
- âœ… Track individual task execution
- âœ… Correlate logs by task_id
- âœ… Debug specific failures
- âœ… Trace task lifecycle

### Logging Levels Comparison

### Option 1: Per-Task Logging âœ… RECOMMENDED

```python
@celery_app.task(bind=True, acks_late=True)
def process_chunk(self: Task, chunk_id: str, job_id: str, user_id: str):
    """Process a single chunk of images."""    # Create task-specific logger with rich context    logger = get_logger().bind(
        task_id=self.request.id,
        task_name=self.name,
        chunk_id=chunk_id,
        job_id=job_id,
        user_id=user_id,
        worker=self.request.hostname,
        retry_count=self.request.retries
    )
    logger.info("Chunk processing started")
    try:
        # Download phase        logger.info("Downloading images", phase="download")
        images = download_images(chunk_id, logger)
        logger.info("Download complete", count=len(images))
        # Validation phase        logger.info("Validating images", phase="validation")
        validated = validate_images(images, logger)
        logger.info("Validation complete", valid=len(validated))
        # Upload phase        logger.info("Uploading to storage", phase="upload")
        upload_to_storage(validated, logger)
        logger.info("Upload complete")
        # Cleanup        cleanup_temp(chunk_id, logger)
        logger.info("Chunk processing completed successfully",
                   duration_sec=time.time() - start_time)
    except Exception as e:
        logger.exception("Chunk processing failed", error=str(e))
        raise
```

### Option 2: Per-Worker Logging âš ï¸ NOT RECOMMENDED

```python
# Worker-level logging (less useful)logger = get_logger().bind(worker="worker1")
logger.info("Worker started")  # Only logs worker lifecycle
```

**Problems:**
- âŒ Canâ€™t distinguish between tasks on same worker
- âŒ Loses task-specific context
- âŒ Hard to debug individual task failures

### Option 3: Per-Thread Logging âœ… POSSIBLE (Advanced)

```python
import threading
from contextvars import ContextVar
# Context variable for request trackingrequest_id: ContextVar[str] = ContextVar('request_id', default='')
@celery_app.task(bind=True)
def process_chunk(self: Task, chunk_id: str):
    # Set context for this execution    request_id.set(self.request.id)
    logger = get_logger().bind(
        task_id=request_id.get(),
        thread_id=threading.get_ident(),
        process_id=os.getpid()
    )
    logger.info("Processing in thread", thread_id=threading.get_ident())
```

**When useful:**
- âœ… Thread-based concurrency (gevent/eventlet)
- âœ… Debugging concurrency issues
- âŒ Overkill for process-based workers

### Worker-Level Logging (Minimal)

```python
from celery.signals import worker_ready, worker_shutdown
@worker_ready.connectdef on_worker_ready(sender, **kwargs):
    logger = get_logger().bind(worker=sender.hostname)
    logger.info("Worker started and ready",
               concurrency=sender.concurrency,
               queues=sender.task_consumer.queues)
@worker_shutdown.connectdef on_worker_shutdown(sender, **kwargs):
    logger = get_logger().bind(worker=sender.hostname)
    logger.info("Worker shutting down")
```

### Log File Organization

**Current Setup (Good):**

```
logs/
â”œâ”€â”€ pixcrawler.log    # All logs
â””â”€â”€ errors.log        # Errors only
```

**Enhanced Setup (Better for Production):**

```
logs/
â”œâ”€â”€ pixcrawler.log    # All logs
â”œâ”€â”€ errors.log        # Errors only
â”œâ”€â”€ tasks/            # Task-specific logs
â”‚   â”œâ”€â”€ 2025-10-30.log
â”‚   â””â”€â”€ 2025-10-31.log
â””â”€â”€ workers/          # Worker-specific logs
    â”œâ”€â”€ worker1.log
    â””â”€â”€ worker2.log
```

**Implementation:**

```python
# Add task-specific file handlerlogger.add(
    "logs/tasks/{time:YYYY-MM-DD}.log",
    level="INFO",
    rotation="00:00",  # Rotate at midnight    retention="30 days",
    filter=lambda record: "task_id" in record["extra"]
)
```

### Best Practices Summary

| What to Log | Level | Context |
| --- | --- | --- |
| Task start/end | INFO | task_id, chunk_id, job_id, user_id |
| Phase transitions | INFO | phase, count, duration |
| Validation results | INFO | valid_count, failed_count |
| Resource usage | DEBUG | memory_mb, disk_mb |
| Errors | ERROR | error, traceback, context |
| Worker lifecycle | INFO | worker, concurrency |

---

## Structured Logging Explained

### Traditional vs.Â Structured Logging

### Traditional Logging (String-based)

```python
# What you might writelogger.info(f"Chunk {chunk_id} processed: {images_valid} valid, {images_failed} failed")
```

**Output (text file):**

```
2025-10-30 22:33:55 | INFO | Chunk chunk_001 processed: 450 valid, 50 failed
```

**Problems:**
- âŒ Hard to parse programmatically
- âŒ Canâ€™t query by specific fields
- âŒ Canâ€™t aggregate metrics easily

### Structured Logging (Key-Value pairs)

```python
# Pass data as keyword argumentslogger.info(
    "Chunk metrics",      # Message    chunk_id=chunk_id,    # Field 1    images_valid=450,     # Field 2    images_failed=50      # Field 3)
```

**Output in Development (text):**

```
2025-10-30 22:33:55 | INFO | Chunk metrics | chunk_id=chunk_001 images_valid=450 images_failed=50
```

**Output in Production (JSON):**

```json
{  "time": "2025-10-30T22:33:55.123Z",  "level": "INFO",  "message": "Chunk metrics",  "chunk_id": "chunk_001",  "images_valid": 450,  "images_failed": 50}
```

**Benefits:**
- âœ… Easy to parse and query
- âœ… Can aggregate metrics
- âœ… Can filter by any field
- âœ… Machine-readable

### How Loguru Handles Structured Logging

```python
from logging_config import get_logger
logger = get_logger()
# Loguru automatically converts kwargs to structured datalogger.info(
    "Chunk processing completed",
    chunk_id="chunk_001",
    images_downloaded=500,
    images_valid=450,
    duration_sec=45.2)
```

**In Development (config.use_json = False):**

```
22:33:55 | INFO | process_chunk:42 - Chunk processing completed | chunk_id=chunk_001 images_downloaded=500 images_valid=450 duration_sec=45.2
```

**In Production (config.use_json = True):**

```json
{  "text": "Chunk processing completed",  "record": {    "elapsed": {"repr": "0:00:45.200000", "seconds": 45.2},    "exception": null,    "extra": {      "chunk_id": "chunk_001",      "images_downloaded": 500,      "images_valid": 450,      "duration_sec": 45.2    },    "file": {"name": "tasks.py", "path": "/app/celery_core/tasks.py"},    "function": "process_chunk",    "level": {"icon": "â„¹ï¸", "name": "INFO", "no": 20},    "line": 42,    "message": "Chunk processing completed",    "module": "tasks",    "name": "celery_core.tasks",    "process": {"id": 1234, "name": "MainProcess"},    "thread": {"id": 5678, "name": "MainThread"},    "time": {"repr": "2025-10-30 22:33:55.123456+03:00", "timestamp": 1730319235.123456}  }}
```

### Practical Example: Analytics from Logs

**In Your Code:**

```python
@celery_app.task(bind=True)
def process_chunk(self: Task, chunk_id: str):
    logger = get_logger().bind(
        task_id=self.request.id,
        chunk_id=chunk_id
    )
    start_time = time.time()
    # Download    images = download_images(chunk_id)
    logger.info("Download phase", images_count=len(images))
    # Validate    valid_images = validate_images(images)
    failed_count = len(images) - len(valid_images)
    # Log with structured data    logger.info(
        "Chunk completed",
        images_downloaded=len(images),
        images_valid=len(valid_images),
        images_failed=failed_count,
        success_rate=len(valid_images) / len(images),
        duration_sec=time.time() - start_time,
        storage_used_mb=calculate_size(valid_images)
    )
```

**Later, Query Programmatically:**

```python
import json
# Find slow chunkswith open('logs/pixcrawler.log') as f:
    for line in f:
        log = json.loads(line)
        if log.get('extra', {}).get('duration_sec', 0) > 60:
            print(f"Slow chunk: {log['extra']['chunk_id']}")
# Calculate average success ratesuccess_rates = []
with open('logs/pixcrawler.log') as f:
    for line in f:
        log = json.loads(line)
        if 'success_rate' in log.get('extra', {}):
            success_rates.append(log['extra']['success_rate'])
avg_success = sum(success_rates) / len(success_rates)
print(f"Average success rate: {avg_success:.2%}")
```

---

## JSON Logs in Production

### Why JSON Logs at Scale?

### The Problem with Text Logs

**Scenario: 1000 users, 10,000 tasks/day**

**Text Logs:**

```
2025-10-30 22:33:55 | INFO | Worker started on worker1
2025-10-30 22:33:56 | INFO | Chunk chunk_001 processing started
2025-10-30 22:34:10 | ERROR | Failed to download image: Connection timeout
2025-10-30 22:34:11 | INFO | Chunk chunk_001 completed: 450 valid, 50 failed
```

**Problems:**
- âŒ Canâ€™t search efficiently - Need regex, grep, awk
- âŒ Canâ€™t aggregate - â€œHow many chunks failed today?â€
- âŒ Canâ€™t correlate - â€œWhich user had the most errors?â€
- âŒ Canâ€™t alert - Hard to trigger alerts on specific conditions
- âŒ Canâ€™t visualize - No easy dashboards

### JSON Logs Enable Log Management

**Example JSON Log:**

```json
{  "time": "2025-10-30T22:33:55Z",  "level": "ERROR",  "message": "Chunk failed",  "chunk_id": "chunk_001",  "user_id": "user_123",  "error": "Connection timeout"}
```

**Tools that consume JSON logs:**
- Azure Monitor / Application Insights (Azure native)
- Datadog
- Splunk
- ELK Stack (Elasticsearch, Logstash, Kibana)
- Grafana Loki

**Query Example (Azure Monitor - KQL):**

```
// Find all errors for user_123
logs
| where user_id == "user_123" and level == "ERROR"
| summarize count() by error

// Alert if error rate > 10%
logs
| where level == "ERROR"
| summarize error_rate = count() / total_count
| where error_rate > 0.1
```

### Real-World Use Cases

### 1. Debugging Production Issues

**Old Way (Manual):**

```bash
# Find why user_123's job failedgrep "user_123" logs/*.log | grep "ERROR" | less# Manual, slow, error-prone
```

â±ï¸ **Time: 30-60 minutes**

**Modern Way (Azure Monitor):**

```
logs
| where user_id == "user_123"
| where level == "ERROR"
| project timestamp, chunk_id, error, task_id
| order by timestamp desc
```

â±ï¸ **Time: 2 minutes**

### 2. Performance Monitoring

```
// Average chunk processing time by hour
logs
| where message == "Chunk completed"
| summarize avg(duration_sec) by bin(timestamp, 1h)
| render timechart

// Slowest chunks today
logs
| where duration_sec > 60
| project chunk_id, duration_sec, images_count
| order by duration_sec desc
```

**Creates automatic dashboards:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Avg Processing Time (last 24h)     â”‚
â”‚                                     â”‚
â”‚ 60s â”¤     â•­â”€â•®                      â”‚
â”‚ 45s â”¤   â•­â”€â•¯ â•°â”€â•®                    â”‚
â”‚ 30s â”¤ â•­â”€â•¯     â•°â”€â•®                  â”‚
â”‚ 15s â”¼â”€â•¯         â•°â”€â”€â”€â”€â”€             â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Alerting

```
// Alert if error rate > 5% in last 5 minutes
logs
| where timestamp > ago(5m)
| summarize
    total = count(),
    errors = countif(level == "ERROR")
| extend error_rate = errors * 100.0 / total
| where error_rate > 5
```

**Triggers:**
- ğŸ“§ Email to team
- ğŸ’¬ Slack notification
- ğŸ“± PagerDuty alert

### 4. Business Metrics

```
// Revenue-impacting metrics
logs
| where message == "Chunk completed"
| summarize
    total_images = sum(images_valid),
    total_jobs = dcount(job_id),
    avg_success_rate = avg(success_rate)
| extend estimated_cost = total_images * 0.001  // $0.001 per image
```

### Cost Comparison

### Without JSON (Manual Analysis)

- Developer time: 2 hours/week debugging logs
- Cost: $100/hour Ã— 2 hours Ã— 52 weeks = **$10,400/year**

### With JSON (Automated)

- Azure Monitor: ~$50/month = $600/year
- Developer time: 15 min/week
- Cost: $600 + ($100/hour Ã— 0.25 hours Ã— 52 weeks) = **$1,900/year**

**Savings: $8,500/year**

---

## Production Logging Workflow

### What You DONâ€™T Do in Production

```bash
# âŒ SSH into serverssh production-server
# âŒ Open log files manuallycd /var/log/pixcrawler
less pixcrawler.log
grep "ERROR" pixcrawler.log
tail -f pixcrawler.log
```

**Why not:**
- âŒ Slow
- âŒ Requires SSH access (security risk)
- âŒ Canâ€™t handle multiple servers
- âŒ No alerting
- âŒ No visualization

### What You DO in Production

```
Your Application (Azure App Service)
         â†“
    JSON Logs
         â†“
Azure Monitor / Application Insights
         â†“
  Dashboard & Alerts
```

**Interact with logs through:**
- ğŸ–¥ï¸ Web Dashboard - Visual interface
- ğŸ” Query Language - Search and filter
- ğŸš¨ Alerts - Automatic notifications
- ğŸ“Š Dashboards - Real-time metrics

### Real Production Scenario

**Scenario:** User reports â€œMy job failedâ€

**Old Way (Manual):**

```bash
1. SSH into server
2. Find the right log file
3. grep for user_id or job_id
4. Read through thousands of lines
5. Try to piece together what happened
```

â±ï¸ **Time: 30-60 minutes**

**Modern Way (Log Management):**

```
1. Open Azure Monitor dashboard
2. Query:
   logs
   | where user_id == "user_123"
   | where job_id == "job_456"
   | where level == "ERROR"
   | order by timestamp desc
3. See results in 2 seconds with full context
```

â±ï¸ **Time: 2 minutes**

### Production Dashboard Example

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PixCrawler - Production Monitoring                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ”´ ALERTS (2)                                       â”‚
â”‚ â€¢ Error rate > 5% in last 5 min                    â”‚
â”‚ â€¢ Chunk processing time > 120s                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“Š METRICS (Last Hour)                              â”‚
â”‚ â€¢ Total Jobs: 1,247                                â”‚
â”‚ â€¢ Success Rate: 97.3%                              â”‚
â”‚ â€¢ Avg Processing Time: 42s                         â”‚
â”‚ â€¢ Active Workers: 35                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ” RECENT ERRORS                                    â”‚
â”‚ 22:35:12 | user_789 | Connection timeout          â”‚
â”‚ 22:33:45 | user_456 | Invalid image format        â”‚
â”‚ 22:31:20 | user_123 | Storage quota exceeded      â”‚
â”‚         [Click to see full trace]                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“ˆ CHARTS                                           â”‚
â”‚ [Processing Time Graph]                            â”‚
â”‚ [Error Rate Graph]                                 â”‚
â”‚ [Active Jobs Graph]                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Automatic Alerts

**Email Alert:**

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Subject: [ALERT] High Error Rate Detected

PixCrawler error rate exceeded 5% threshold

Details:
- Time: 2025-10-30 22:35:00
- Error Rate: 7.2%
- Affected Users: 12
- Top Error: Connection timeout (8 occurrences)

View Dashboard: [Link]
Query Logs: [Link]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Slack Notification:**

```
ğŸ”´ PixCrawler Alert
Error rate: 7.2% (threshold: 5%)
Last 5 min: 18 errors / 250 requests
Top error: Connection timeout
[View Details]
```

---

## Azure Monitor Deep Dive

### What is Azure Monitor?

Azure Monitor = **Log Storage + Analysis Tools**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Azure Monitor                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Log Storage (Log Analytics Workspace)   â”‚
â”‚    â€¢ Stores your JSON logs                 â”‚
â”‚    â€¢ Retention: 30-730 days                â”‚
â”‚    â€¢ Indexed for fast search               â”‚
â”‚                                             â”‚
â”‚ 2. Query Engine                             â”‚
â”‚    â€¢ Search logs with KQL language         â”‚
â”‚    â€¢ Fast queries (seconds)                â”‚
â”‚                                             â”‚
â”‚ 3. Dashboards                               â”‚
â”‚    â€¢ Visualize metrics                     â”‚
â”‚    â€¢ Charts and graphs                     â”‚
â”‚                                             â”‚
â”‚ 4. Alerts                                   â”‚
â”‚    â€¢ Automatic notifications               â”‚
â”‚    â€¢ Email, Slack, etc.                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How Logs Flow to Azure Monitor

```
1. Your App (Azure App Service)
   â†“
   Writes JSON to stdout/stderr

2. Azure App Service
   â†“
   Automatically sends logs to â†’

3. Azure Monitor (Log Analytics Workspace)
   â†“
   Stores logs in a database

4. You Access Via:
   - Azure Portal (web interface)
   - Query logs with KQL
   - View dashboards
   - Get alerts
```

### Storage Comparison

### Blob Storage (Data Lake)

**What:** File storage (like Dropbox)

**How:** Upload/download files

**Access:** Download file â†’ open â†’ read

**Cost:** $0.02/GB/month

**Use for:** Images, datasets, archives

### Azure Monitor (Log Analytics)

**What:** Log database + analysis tools

**How:** Logs automatically ingested

**Access:** Query through web interface

**Cost:** $2-3/GB ingested

**Use for:** Application logs, monitoring

### Concrete Example

**Scenario: Your app runs for 1 day**

**What happens:**

```
Your App generates logs:
â”œâ”€â”€ 10,000 log entries
â”œâ”€â”€ ~500 MB of JSON logs
â””â”€â”€ Sent to Azure Monitor

Azure Monitor:
â”œâ”€â”€ Receives 500 MB
â”œâ”€â”€ Stores in Log Analytics Workspace
â”œâ”€â”€ Indexes all fields (task_id, user_id, etc.)
â”œâ”€â”€ Retention: 30 days (default)
â””â”€â”€ Cost: ~$1.50 for that day
```

**You can now:**

```
// Query in Azure Portal
logs
| where timestamp > ago(1d)
| where level == "ERROR"
| summarize count() by error
```

**Result in 2 seconds:**
| error | count |
|â€”â€”-|â€”â€”-|
| Connection timeout | 12 |
| Invalid image format | 5 |
| Storage quota exceeded | 2 |

### Azure Portal Interface

**Where You See It:**

1. Go to: `portal.azure.com`
2. Navigate to: Azure Monitor â†’ Logs
3. See your logs in a table:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query: logs | where level == "ERROR"             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ timestamp           level  message      user_id  â”‚
â”‚ 2025-10-30 22:35:00 ERROR  Timeout     user_123 â”‚
â”‚ 2025-10-30 22:33:45 ERROR  Invalid     user_456 â”‚
â”‚ 2025-10-30 22:31:20 ERROR  Quota       user_789 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. Click any row â†’ See full details
2. Create charts, dashboards, alerts

### Cost Breakdown

**Azure Monitor Pricing:**
- Log Ingestion: $2.76/GB
- Data Retention:
- First 31 days: Free
- 31-730 days: $0.12/GB/month

**Example (100 users, 1GB logs/day):**
- Ingestion: 1GB Ã— 30 days Ã— $2.76 = $82.80/month
- Retention (30 days): Free
- **Total: ~$83/month**

**What you get:**
- âœ… Logs stored for 30 days
- âœ… Fast querying
- âœ… Dashboards
- âœ… Alerts
- âœ… No manual work

### Setup (Automatic)

**When you deploy to Azure App Service:**

1. Azure automatically creates:
    - Application Insights (part of Azure Monitor)
    - Log Analytics Workspace (storage)
2. Your app writes logs to stdout:
    
    ```python
    logger.info("message")
    ```
    
3. Azure captures and stores them automatically
4. You access via Azure Portal

**No extra configuration needed!**

---

## Storage Strategy

### Correct Architecture: Separate Concerns

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Application Logs                 â”‚
â”‚  (Operational, debugging, monitoring)   â”‚
â”‚                                         â”‚
â”‚  Azure Monitor / Application Insights   â”‚
â”‚  â€¢ Real-time querying                  â”‚
â”‚  â€¢ Alerting                            â”‚
â”‚  â€¢ Dashboards                          â”‚
â”‚  â€¢ 30-90 day retention                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Dataset Files                    â”‚
â”‚     (User data, deliverables)           â”‚
â”‚                                         â”‚
â”‚  Azure Blob Storage (Data Lake)         â”‚
â”‚  â€¢ Images                              â”‚
â”‚  â€¢ Metadata (JSON)                     â”‚
â”‚  â€¢ Labels                              â”‚
â”‚  â€¢ README                              â”‚
â”‚  â€¢ Long-term storage                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Goes Where

### Azure Monitor (Operational Logs)

```json
{  "timestamp": "2025-10-30T22:35:00Z",  "level": "INFO",  "message": "Chunk completed",  "task_id": "abc-123",  "chunk_id": "chunk_001",  "job_id": "job_456",  "user_id": "user_789",  "images_processed": 450,  "duration_sec": 42.5}
```

**Purpose:** Debugging, monitoring, alerting

### Blob Storage (Dataset Metadata)

```json
{  "dataset_id": "dataset_001",  "created_at": "2025-10-30T22:00:00Z",  "user_id": "user_789",  "total_images": 2000,  "keywords": ["cat", "dog"],  "statistics": {    "valid_images": 1950,    "failed_images": 50,    "avg_size_mb": 2.5  },  "processing_summary": {    "total_duration_sec": 850,    "chunks_processed": 4,    "validation_passed": 1950  }}
```

**Purpose:** Dataset information for users

### What Users Need in Datasets

**In the Dataset (Blob Storage):**

```
dataset_001/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ cat_001.jpg
â”‚   â”œâ”€â”€ cat_002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ labels.json
â”‚   â””â”€â”€ labels.csv
â”œâ”€â”€ metadata.json      â† Summary info
â””â”€â”€ README.md          â† Human-readable info
```

**metadata.json (What users care about):**

```json
{  "dataset_id": "dataset_001",  "created_at": "2025-10-30T22:00:00Z",  "total_images": 2000,  "keywords": ["cat", "dog"],  "quality_score": 0.975,  "processing_info": {    "completion_time": "2025-10-30T22:14:10Z",    "total_duration_minutes": 14,    "sources": ["google", "bing"]  }}
```

**Users DONâ€™T need:**
- âŒ Full application logs
- âŒ Task execution details
- âŒ Worker information
- âŒ Debug messages

### Hybrid Approach (Optional)

**If you want to give users processing info:**

```
dataset_001/
â”œâ”€â”€ images/
â”œâ”€â”€ labels/
â”œâ”€â”€ metadata.json           â† Summary
â””â”€â”€ processing_report.json  â† High-level report
```

**processing_report.json:**

```json
{  "job_id": "job_456",  "started_at": "2025-10-30T22:00:00Z",  "completed_at": "2025-10-30T22:14:10Z",  "total_duration_minutes": 14,  "chunks": [    {      "chunk_id": "chunk_001",      "images_downloaded": 500,      "images_valid": 487,      "duration_sec": 42    },    {      "chunk_id": "chunk_002",      "images_downloaded": 500,      "images_valid": 475,      "duration_sec": 45    }  ],  "summary": {    "total_images": 2000,    "valid_images": 1950,    "success_rate": 0.975  }}
```

**This is:**
- âœ… User-friendly summary
- âœ… Stored with dataset
- âœ… Small file size
- âŒ NOT full application logs

### Why NOT Blob Storage for Application Logs?

### Problems with Logs in Blob Storage

**1. No Query Capability**

```
Blob Storage (Data Lake):
â”œâ”€â”€ dataset_001/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ logs/
â”‚       â””â”€â”€ 2025-10-30.log  â† JSON file
â””â”€â”€ dataset_002/
    â””â”€â”€ logs/
        â””â”€â”€ 2025-10-30.log
```

**Problem:** How do you find â€œall errors for user_123â€?
- âŒ Canâ€™t query across blobs
- âŒ Need to download and parse each file
- âŒ No indexing
- âŒ No real-time search

**2. No Alerting**

```
User's job fails at 22:35
    â†“
Logs written to blob storage
    â†“
    ...
    â†“
Nobody knows until user complains
```

- âŒ No way to trigger alerts from blob storage

**3. Slow Access**

To find an error:
1. List all blob directories
2. Download each log file
3. Parse JSON locally
4. Search manually

â±ï¸ **Time: Minutes to hours**
ğŸ’° **Cost: Download bandwidth charges**

**4. No Aggregation**

**Question:** â€œWhatâ€™s the average processing time today?â€

**With Blob Storage:**
1. Download all log files
2. Parse all JSON
3. Calculate manually

â±ï¸ **Time: 30+ minutes**

**With Azure Monitor:**

```
summarize avg(duration_sec)
```

â±ï¸ **Time: 2 seconds**

### Cost Comparison: Blob vs Azure Monitor

### Option 1: Logs in Blob Storage âŒ

**Storage:** $0.02/GB/month

For 1GB logs/day Ã— 30 days = $0.60/month

**But:**
- âŒ No querying
- âŒ No alerting
- âŒ No dashboards
- âŒ Manual analysis required

Developer time: $100/hour Ã— 2 hours/week = $800/month

**Total: $800.60/month**

### Option 2: Azure Monitor âœ…

**Ingestion:** $2-3/GB

For 1GB logs/day Ã— 30 days = $60-90/month

**Includes:**
- âœ… Real-time querying
- âœ… Automatic alerting
- âœ… Dashboards
- âœ… No manual work

Developer time: $100/hour Ã— 0.25 hours/week = $100/month

**Total: $160-190/month**

**Savings: $600-640/month**

### Recommendation Summary

**DO:**
- âœ… Application logs â†’ Azure Monitor (operational)
- âœ… Dataset metadata â†’ Blob Storage (user deliverable)
- âœ… Processing summary â†’ Blob Storage (optional, user-friendly)

**DONâ€™T:**
- âŒ Store full application logs in Blob Storage
- âŒ Mix operational logs with user data
- âŒ Try to query logs from Blob Storage

**Remember:** Data Lake has no processing power, so it canâ€™t:
- Query logs efficiently
- Trigger alerts
- Create dashboards
- Aggregate metrics

---

## Query Language & Tools

### Do You Have to Use KQL?

**Short Answer:** Depends on the tool, but most have query languages.

| Tool | Query Language | Alternative |
| --- | --- | --- |
| Azure Monitor | KQL (Kusto Query Language) | âŒ No alternative |
| Datadog | Datadog Query Language | Web UI filters |
| Grafana Loki | LogQL | Web UI filters |
| ELK Stack | Lucene / KQL | Kibana UI |
| Splunk | SPL (Search Processing Language) | Web UI |

### KQL Basics (Actually Simple!)

```
// Find errors
logs | where level == "ERROR"

// Count by user
logs | summarize count() by user_id

// Average duration
logs | summarize avg(duration_sec)

// Time range
logs | where timestamp > ago(1h)

// Complex query
logs
| where level == "ERROR"
| where timestamp > ago(24h)
| summarize error_count = count() by user_id, error
| order by error_count desc
| take 10
```

**Most tools also have:**
- âœ… Web UI with point-and-click filters (no code)
- âœ… Query language for advanced searches

### Query Examples (Azure Monitor)

### 1. Find Why a Job Failed

```
logs
| where job_id == "job_12345"
| project timestamp, level, message, chunk_id, error
| order by timestamp asc
```

**Result (in 2 seconds):**

| timestamp | level | message | chunk_id | error |
| --- | --- | --- | --- | --- |
| 2025-10-30 22:30:00 | INFO | Job started | - | - |
| 2025-10-30 22:30:05 | INFO | Chunk processing | chunk_001 | - |
| 2025-10-30 22:30:45 | INFO | Chunk completed | chunk_001 | - |
| 2025-10-30 22:31:00 | INFO | Chunk processing | chunk_002 | - |
| 2025-10-30 22:31:15 | ERROR | Chunk failed | chunk_002 | Connection timeout |
| 2025-10-30 22:31:16 | ERROR | Job failed | - | Max retries exceeded |

### 2. Performance Analysis

```
logs
| where message == "Chunk completed"
| summarize
    avg_duration = avg(duration_sec),
    max_duration = max(duration_sec),
    count = count()
  by bin(timestamp, 1h)
| render timechart
```

**Result:** Interactive chart showing performance trends

### 3. User Impact Analysis

```
logs
| where level == "ERROR"
| summarize error_count = count() by user_id
| order by error_count desc
| take 10
```

**Result:** Top 10 users with most errors

### Log Querying Tools

### Local Development (File-based)

```bash
# JSON logs (if you have them locally)jq 'select(.task_id == "abc-123")' logs/pixcrawler.log
# Text logsgrep "task_id=abc-123" logs/pixcrawler.log
# Find all errorsjq 'select(.level == "ERROR")' logs/errors.log
# Track a job across chunksjq 'select(.job_id == "job_456")' logs/pixcrawler.log
```

### Log Storage Structure

**Question:** Do Azure Monitor/vendors have a filesystem?

**Answer:** NO - Itâ€™s a DATABASE, not files

### Traditional (File-based):

```
logs/
â”œâ”€â”€ 2025-10-30/
â”‚   â”œâ”€â”€ worker1.log
â”‚   â””â”€â”€ worker2.log
â””â”€â”€ 2025-10-31/
    â””â”€â”€ worker1.log
```

### Modern (Database):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Log Database (Indexed Table)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ timestamp | level | task_id | msg  â”‚
â”‚ 22:35:00  | INFO  | abc-123 | ...  â”‚
â”‚ 22:35:01  | ERROR | abc-124 | ...  â”‚
â”‚ 22:35:02  | INFO  | abc-125 | ...  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How Logs Are Structured

**Not by filename, but by FIELDS:**

```json
{  "timestamp": "2025-10-30T22:35:00Z",  "level": "ERROR",  "task_id": "abc-123",  "chunk_id": "chunk_001",  "job_id": "job_456",  "user_id": "user_789",  "message": "Chunk failed",  "error": "Connection timeout"}
```

**All fields are indexed, query by ANY field:**

```
// Query by task_id
logs | where task_id == "abc-123"

// Query by user_id
logs | where user_id == "user_789"

// Query by time range
logs | where timestamp > ago(1h)
```

**No need to organize into folders!**

### Log Naming

**Question:** Should we name logs like `{task_id}/{year}/{month}{day}`?

**Answer:** You DONâ€™T name logs in database-based systems

### Old Way (File-based logging):

```
logs/
â”œâ”€â”€ tasks/
â”‚   â””â”€â”€ abc-123/
â”‚       â””â”€â”€ 2025/
â”‚           â””â”€â”€ 10/
â”‚               â””â”€â”€ 30.log
```

### Modern Way (Database logging):

Just log with context:

```python
logger.info(
    "Chunk completed",
    task_id="abc-123",
    chunk_id="chunk_001",
    job_id="job_456",
    user_id="user_789")
```

The system automatically:
- âœ… Adds timestamp
- âœ… Indexes all fields
- âœ… Makes it searchable

To find logs for a specific task:

```
// No need to know filename
logs | where task_id == "abc-123"
```

### Alternative Log Management Tools

### Option 1: Azure Monitor âœ… RECOMMENDED for Azure

**Pros:**
- âœ… Native Azure integration (automatic setup)
- âœ… No extra infrastructure (managed service)
- âœ… Works out of the box with App Service
- âœ… Integrated with Azure ecosystem
- âœ… Good pricing for small-medium scale

**Cons:**
- âŒ Locked to Azure (vendor lock-in)
- âŒ KQL required for advanced queries
- âŒ Less flexible than open-source

**Cost:** $2.76/GB ingested, First 5GB/month free, ~$50-100/month for 100 users

**Best for:**
- âœ… Youâ€™re already on Azure
- âœ… Want simple setup
- âœ… Donâ€™t need multi-cloud

### Option 2: Grafana Loki âœ… BEST for Open Source

**Pros:**
- âœ… Open source (no vendor lock-in)
- âœ… Lightweight (less resource-intensive)
- âœ… Works anywhere (local, Azure, AWS, GCP)
- âœ… Great UI (Grafana dashboards)
- âœ… Cost-effective (self-hosted or cloud)

**Cons:**
- âŒ Self-managed (you run it)
- âŒ More setup required
- âŒ Need to manage infrastructure

**Cost:** Self-hosted: ~$20-50/month (VM costs), Grafana Cloud: $0.50/GB ingested

**Best for:**
- âœ… Want flexibility
- âœ… Multi-cloud or hybrid
- âœ… Open-source preference

**Setup:**

```yaml
# docker-compose.ymlservices:  loki:    image: grafana/loki:latest    ports:      - "3100:3100"  grafana:    image: grafana/grafana:latest    ports:      - "3000:3000"
```

### Option 3: Datadog ğŸ’° BEST for Enterprise

**Pros:**
- âœ… Best-in-class UI (amazing dashboards)
- âœ… APM + Logs + Metrics (all-in-one)
- âœ… Great alerting and integrations
- âœ… Multi-cloud support

**Cons:**
- âŒ Expensive ($15-31/host/month + $0.10/GB)
- âŒ Overkill for small projects

**Cost:** ~$200-500/month for 100 users

**Best for:**
- âœ… Enterprise with budget
- âœ… Need advanced features
- âœ… Multi-cloud monitoring

### Option 4: ELK Stack (Elasticsearch, Logstash, Kibana)

**Pros:**
- âœ… Powerful search (Elasticsearch)
- âœ… Flexible and customizable
- âœ… Open source

**Cons:**
- âŒ Resource-heavy (needs 4-8GB RAM minimum)
- âŒ Complex setup and maintenance
- âŒ Expensive to run (infrastructure costs)

**Cost:** Self-hosted: $100-300/month, Elastic Cloud: $95-500/month

**Best for:**
- âœ… Large scale (TB of logs)
- âœ… Complex search requirements
- âŒ NOT recommended for your scale

### Option 5: Simple File Logging + Blob Storage âš ï¸ Budget Option

**Pros:**
- âœ… Cheapest ($0.02/GB/month)
- âœ… Simple (no external service)

**Cons:**
- âŒ No querying (manual search)
- âŒ No alerting
- âŒ No dashboards
- âŒ Not scalable

**Only use if:**
- Very small scale (<10 users)
- Tight budget
- Donâ€™t need monitoring

### Tool Comparison Table

| Tool | Setup | Cost/month | Query | Best For |
| --- | --- | --- | --- | --- |
| Azure Monitor | â­â­â­â­â­ Auto | $50-100 | KQL | Azure users |
| Grafana Loki | â­â­â­ Medium | $20-50 | LogQL | Open source |
| Datadog | â­â­â­â­ Easy | $200-500 | DQL | Enterprise |
| ELK Stack | â­ Hard | $100-300 | Lucene | Large scale |
| File Logs | â­â­â­â­â­ Easy | $1-5 | grep | Tiny projects |

### Recommendation Phases

**Phase 1: MVP (Now)**
- **Use:** Azure Monitor / Application Insights
- **Why:** Already on Azure, zero setup, good for 100-1000 users
- **Cost:** ~$50-100/month

**Phase 2: Growth (1000+ users)**
- **Consider:** Grafana Loki (self-hosted on Azure)
- **Why:** More cost-effective at scale, better flexibility, no vendor lock-in
- **Cost:** ~$50-100/month (infrastructure)

**Phase 3: Enterprise (10,000+ users)**
- **Consider:** Datadog or keep Grafana Loki
- **Why:** Advanced features needed, budget available, multi-cloud support
- **Cost:** $500-1000/month

---

## Configuration Split

### Development vs Production Configuration

Your logging configuration is split between development and production environments.

### Development (Your Code Controls Everything)

```python
# logging_config/config.pyif environment == Environment.DEVELOPMENT:
    self.console_level = LogLevel.DEBUG
    self.file_level = LogLevel.DEBUG
    self.use_json = False    self.use_colors = True    # File handlers YOU control    logger.add(
        "logs/pixcrawler.log",
        level="DEBUG",
        rotation="10 MB",      # â† You control        retention=5,           # â† You control (5 files)        serialize=False        # â† Text format    )
```

**You manage:**
- âœ… Log levels
- âœ… File rotation
- âœ… Retention (how many files to keep)
- âœ… Format (text vs JSON)
- âœ… Where files are stored

### Production (Azure Monitor Controls Storage)

```python
# logging_config/config.pyif environment == Environment.PRODUCTION:
    self.console_level = LogLevel.WARNING
    self.file_level = LogLevel.INFO
    self.use_json = True      # â† JSON for Azure    self.use_colors = False    # Only configure OUTPUT format    logger.add(
        sys.stdout,            # â† Write to stdout        level="INFO",
        serialize=True         # â† JSON format    )
    # NO file handlers needed!
```

**Azure Monitor manages:**
- âœ… Storage location
- âœ… Retention (30-730 days via Azure settings)
- âœ… Indexing
- âœ… Backup
- âœ… Compression

**Your code only:**
- âœ… Formats logs as JSON
- âœ… Writes to stdout/stderr
- âœ… Sets log level

### Data Flow Comparison

### Development Flow:

```
Your App
    â†“
logger.info("message")
    â†“
Loguru writes to:
  - Console (colored, DEBUG level)
  - logs/pixcrawler.log (rotated, 5 backups)
  - logs/errors.log (errors only)
    â†“
You manage files manually
```

### Production Flow:

```
Your App (Azure App Service)
    â†“
logger.info("message")
    â†“
Loguru writes JSON to stdout
    â†“
Azure App Service captures stdout
    â†“
Sends to Azure Monitor automatically
    â†“
Azure Monitor:
  - Stores in Log Analytics
  - Indexes all fields
  - Retains for 30 days (configurable)
  - Makes queryable
```

### Configuration Comparison Table

| Setting | Development (Your Code) | Production (Azure) |
| --- | --- | --- |
| Log Level | âœ… Your code | âœ… Your code |
| Format | âœ… Your code (text) | âœ… Your code (JSON) |
| Output | âœ… Your code (files) | âœ… Your code (stdout) |
| Storage | âœ… Your code (local disk) | âŒ Azure manages |
| Rotation | âœ… Your code (10 MB) | âŒ Azure manages |
| Retention | âœ… Your code (5 files) | âŒ Azure manages |
| Indexing | âŒ None | âŒ Azure manages |
| Querying | âŒ grep/less | âŒ Azure provides |

### Simplified Production Config

Your production logging config becomes VERY simple:

```python
# logging_config/config.py - Productiondef setup_logging(environment: Environment.PRODUCTION):
    logger.remove()  # Remove defaults    # Single handler: JSON to stdout    logger.add(
        sys.stdout,
        level="INFO",
        serialize=True,      # JSON format        format="{message}"   # Let Azure handle formatting    )
    # That's it! Azure handles the rest
```

**Everything else (storage, retention, indexing, querying) is in Azure Portal.**

### Azure Monitor Retention Settings

**Configure in Azure Portal:**

1. Go to: Log Analytics Workspace
2. Settings â†’ Usage and estimated costs
3. Data Retention: 30-730 days
4. Archive: Move old logs to cheaper storage

**Pricing tiers:**

**Interactive (Hot):**
- 30 days: Included in ingestion cost
- 31-90 days: $0.12/GB/month
- Fast queries

**Archive (Cold):**
- 90+ days: $0.02/GB/month
- Slower queries
- Cheaper storage

### Environment Configuration Comparison

| Environment | Console (stderr) | Files | stdout |
| --- | --- | --- | --- |
| Development | âœ… Colored DEBUG | âœ… Rotated files | âŒ |
| Production | âœ… WARNING only | âŒ | âœ… JSON |
| Testing | âœ… ERROR only | âŒ | âŒ |

---

## Implementation Changes

### Changes Made to logging_config/config.py

### 1. Production Now Uses stdout (Not Files)

**Before:**

```python
# Production wrote to files (wrong for Azure)logger.add(
    config.log_dir / config.log_filename,
    serialize=True  # JSON to file)
```

**After:**

```python
# Production writes JSON to stdout (correct for Azure)if config.environment == Environment.PRODUCTION:
    logger.add(
        sys.stdout,
        level=config.file_level.value,
        format="{message}",
        serialize=True,  # JSON format        filter=_package_filter
    )
```

### 2. Log Directory Only Created for Development

**Before:**

```python
# Always created logs directoryconfig.log_dir.mkdir(parents=True, exist_ok=True)
```

**After:**

```python
# Only create for non-productionif config.environment != Environment.PRODUCTION:
    config.log_dir.mkdir(parents=True, exist_ok=True)
```

### How It Works Now

**Development:**

```python
setup_logging(environment='development')
```

**Outputs:**
- âœ… Console (stderr): Colored, DEBUG level
- âœ… File (logs/pixcrawler.log): Text format, rotated
- âœ… File (logs/errors.log): Errors only

**Production:**

```python
setup_logging(environment='production')
```

**Outputs:**
- âœ… Console (stderr): Warnings only (for debugging)
- âœ… Stdout: JSON format â†’ Azure Monitor captures this
- âŒ No files created (Azure manages storage)

**Testing:**

```python
setup_logging(environment='testing')
```

**Outputs:**
- âœ… Console (stderr): Errors only
- âŒ No files

### Azure Monitor Setup Code

**Question:** Do we need Azure Monitor setup code?

**Answer:** NO - Zero code needed!

**What Azure does automatically:**
- âœ… Creates Application Insights when you deploy
- âœ… Captures stdout/stderr from your app
- âœ… Stores in Log Analytics Workspace
- âœ… Indexes all JSON fields
- âœ… Makes logs queryable

**Your code is already complete** - The changes to `logging_config/config.py` are all you need.

**How it works:**

```python
# Your code (already done)setup_logging(environment='production')
logger.info("message", key=value)
# Azure automatically:# - Captures JSON from stdout# - Sends to Azure Monitor# - Makes it queryable
```

**No SDK, no config files, no Azure-specific code required!**

---

## Deployment Checklist

### Azure Configuration Files Status

### 1. .env.example.azure âœ… Updated

**Added:**

```bash
# LoggingPIXCRAWLER_ENVIRONMENT=production
```

This ensures JSON logging is enabled in production.

### 2. .deployignore âœ… Perfect

**Already excludes:**
- âœ… Development files
- âœ… Tests
- âœ… Documentation
- âœ… Frontend (deployed separately)

**Logs are NOT excluded** - Good! Azure needs to see your appâ€™s stdout.

### 3. .deployment âœ… Perfect

Points to `startup-azure.sh` - correct setup.

### 4. startup-azure.sh âœ… Perfect

**What it does:**
- âœ… Installs UV and dependencies
- âœ… Starts Redis (for Celery)
- âœ… Starts Celery worker
- âœ… Starts FastAPI with Gunicorn

**Logging is automatic:**

```bash
--access-logfile - --error-logfile -
```

This sends logs to stdout/stderr - Azure captures them automatically.

**No changes needed!**

### Deployment Steps

### When Deploying to Azure:

**1. Set Environment Variable in Azure Portal:**

Navigate to:

```
Azure Portal â†’ Your App Service â†’ Configuration â†’ Application Settings
```

Add:

```
Name: PIXCRAWLER_ENVIRONMENT
Value: production
```

**2. Deploy your application**

**3. Verify logs (2-5 min delay):**

```
Azure Portal â†’ Your App Service â†’ Application Insights â†’ Logs
```

### Complete Checklist

**Code (Already Done):**
- âœ… `logging_config/config.py` - Updated for production
- âœ… `.env.example.azure` - Added logging env var

**Azure Portal (When Deploying):**
- â¬œ Set `PIXCRAWLER_ENVIRONMENT=production` in Application Settings
- â¬œ Verify Application Insights is created (automatic)
- â¬œ Check logs appear in Azure Monitor (2-5 min delay)

**No other configuration files needed!**

### Verification Steps

After deployment, verify logging is working:

**1. Check Application Insights:**

```
Azure Portal â†’ Application Insights â†’ Logs
```

**2. Run a test query:**

```
traces
| where timestamp > ago(1h)
| take 10
```

**3. Verify JSON structure:**

```
traces
| where timestamp > ago(1h)
| project timestamp, message, customDimensions
| take 1
```

**4. Check for your custom fields:**

```
traces
| where timestamp > ago(1h)
| where customDimensions.task_id != ""
| take 10
```

---

## Summary

### Key Takeaways

**Logging Strategy:**
- âœ… Use per-task logging with rich context
- âœ… Bind task_id, chunk_id, job_id, user_id to every log
- âœ… Use structured logging (JSON in production)
- âŒ Donâ€™t log per-thread (unnecessary complexity)

**Structured Logging:**
- âœ… Pass data as keyword arguments to logger
- âœ… Loguru stores them in the extra field
- âœ… In production, logs are JSON (machine-readable)
- âœ… Query and analyze logs programmatically

**JSON Logs in Production:**
- âœ… Enable log management tools (Azure Monitor, Datadog, etc.)
- âœ… Fast searching - Index all fields, query in seconds
- âœ… Automatic dashboards - Visualize metrics without code
- âœ… Alerting - Trigger alerts on specific conditions
- âœ… Cost savings - Less developer time debugging

**Azure Monitor:**
- âœ… Log storage + analysis tools
- âœ… Automatic integration with Azure App Service
- âœ… No code changes needed
- âœ… Query with KQL, create dashboards, set up alerts

**Storage Strategy:**
- âœ… Application logs â†’ Azure Monitor (operational)
- âœ… Dataset metadata â†’ Blob Storage (user deliverable)
- âŒ Donâ€™t store application logs in Blob Storage

**Configuration:**
- âœ… Development: Full control with file rotation
- âœ… Production: Only format (JSON) and output (stdout)
- âœ… Azure manages storage, retention, indexing

**Deployment:**
- âœ… Set `PIXCRAWLER_ENVIRONMENT=production` in Azure
- âœ… No other code or configuration needed
- âœ… Logs automatically flow to Azure Monitor

### Your Logging is Production-Ready! ğŸš€

The logging system is now optimized for both local development and Azure production deployment, with zero additional Azure-specific code required.