# PixCrawler üï∑Ô∏è - Configurable Image Dataset Builder

PixCrawler is a customizable image dataset builder that crawls the web using popular search engines like Google, Bing, and DuckDuckGo. It enables researchers, ML engineers, and developers to automate the collection of images for training datasets using a simple JSON-based configuration file.

## üìö Features

* **JSON-driven configuration**
  * Define dataset name, categories, and keywords for search
* **Multi-engine support**
  * Uses Google, Bing, Baidu, and DuckDuckGo as fallback
* **Fast concurrent crawling**
  * Efficient image scraping using parallel downloads
* **Organized dataset structure**
  * Images are grouped by category and keyword
* **Duplicate detection**
  * Automatically removes duplicates using content and perceptual hashing
* **Progress tracking**
  * Continue from where you left off with progress caching
* **Keyword Generation**
  * Automatically generate effective keywords when none are provided
  * Optionally augment user-provided keywords with additional generated ones

## üîß Usage

Create a config file following the example in `config.json.example`:

```json
{
  "dataset_name": "animals",
  "categories": {
    "mammals": [
      "dog",
      "cat",
      "elephant"
    ],
    "birds": [
      "eagle",
      "penguin",
      "parrot"
    ]
  }
}
```

Then run:

```bash
python main.py -c config.json -m 20
```

This will create a dataset with the following structure:

```
animals/
‚îú‚îÄ‚îÄ mammals/
‚îÇ   ‚îú‚îÄ‚îÄ dog/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 001.jpg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 002.jpg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ cat/
‚îÇ   ‚îî‚îÄ‚îÄ elephant/
‚îî‚îÄ‚îÄ birds/
    ‚îú‚îÄ‚îÄ eagle/
    ‚îú‚îÄ‚îÄ penguin/
    ‚îî‚îÄ‚îÄ parrot/
```

## üöÄ Command Line Arguments

```
python main.py --help
```

- `-c, --config`: Path to configuration file (required)
- `-m, --max-images`: Maximum number of images per keyword (default: 10)
- `-o, --output`: Custom output directory (default: uses dataset_name from config)
- `--no-integrity`: Skip integrity checks
- `-r, --max-retries`: Maximum retry attempts (default: 5)
- `--continue`: Continue from last run
- `--cache`: Cache file for progress tracking (default: download_progress.json)
- `--generate-keywords`: Generate additional keywords for categories (even when user-provided)
- `--no-generate-keywords`: Disable automatic keyword generation

## üåü Acknowledgements

* Google, Bing, and Baidu image search APIs
* DuckDuckGo search
* Python requests & icrawler

> Built with ‚ù§Ô∏è by [Alaamer](https://github.com/alaamer12)
