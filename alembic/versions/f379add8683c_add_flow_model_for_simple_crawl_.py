"""Add Flow model for simple crawl operations

Revision ID: f379add8683c
Revises: f002ea45b128
Create Date: 2025-12-11 13:24:33.042494

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'f379add8683c'
down_revision: Union[str, None] = 'f002ea45b128'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_policy_execution_logs_dataset_id'), table_name='policy_execution_logs')
    op.drop_index(op.f('ix_policy_execution_logs_policy_id'), table_name='policy_execution_logs')
    op.drop_index(op.f('ix_policy_logs_executed_at'), table_name='policy_execution_logs')
    op.drop_index(op.f('ix_policy_logs_type_status'), table_name='policy_execution_logs')
    op.drop_table('policy_execution_logs')
    op.drop_index(op.f('ix_cleanup_policies_is_active'), table_name='cleanup_policies')
    op.drop_table('cleanup_policies')
    op.drop_index(op.f('ix_archival_policies_is_active'), table_name='archival_policies')
    op.drop_table('archival_policies')
    op.drop_constraint(op.f('crawl_jobs_dataset_id_datasets_id_fk'), 'crawl_jobs', type_='foreignkey')
    op.drop_index(op.f('ix_notifications_created_at'), table_name='notifications')
    op.create_index('ix_notifications_created_at', 'notifications', ['created_at'], unique=False, postgresql_using='btree', postgresql_ops={'created_at': 'DESC'})
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('ix_notifications_created_at', table_name='notifications', postgresql_using='btree', postgresql_ops={'created_at': 'DESC'})
    op.create_index(op.f('ix_notifications_created_at'), 'notifications', [sa.literal_column('created_at DESC')], unique=False)
    op.create_foreign_key(op.f('crawl_jobs_dataset_id_datasets_id_fk'), 'crawl_jobs', 'datasets', ['dataset_id'], ['id'], ondelete='SET NULL')
    op.create_table('archival_policies',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('is_active', sa.BOOLEAN(), server_default=sa.text('true'), autoincrement=False, nullable=False),
    sa.Column('days_until_archive', sa.INTEGER(), autoincrement=False, nullable=False, comment='Days since creation or last access before archiving'),
    sa.Column('target_tier', sa.VARCHAR(length=20), autoincrement=False, nullable=False, comment='Target storage tier: hot, warm, cold'),
    sa.Column('filter_criteria', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True, comment="Criteria to filter datasets (e.g., {'project_id': 1})"),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False, comment='Timestamp when record was created'),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False, comment='Timestamp when record was last updated'),
    sa.PrimaryKeyConstraint('id', name=op.f('archival_policies_pkey')),
    sa.UniqueConstraint('name', name=op.f('archival_policies_name_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.create_index(op.f('ix_archival_policies_is_active'), 'archival_policies', ['is_active'], unique=False)
    op.create_table('cleanup_policies',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('is_active', sa.BOOLEAN(), server_default=sa.text('true'), autoincrement=False, nullable=False),
    sa.Column('days_until_cleanup', sa.INTEGER(), autoincrement=False, nullable=False, comment='Days since creation/completion before cleanup'),
    sa.Column('cleanup_target', sa.VARCHAR(length=50), autoincrement=False, nullable=False, comment='Target: full_dataset, temp_files, failed_jobs'),
    sa.Column('filter_criteria', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True, comment='Criteria to filter datasets'),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False, comment='Timestamp when record was created'),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False, comment='Timestamp when record was last updated'),
    sa.PrimaryKeyConstraint('id', name=op.f('cleanup_policies_pkey')),
    sa.UniqueConstraint('name', name=op.f('cleanup_policies_name_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.create_index(op.f('ix_cleanup_policies_is_active'), 'cleanup_policies', ['is_active'], unique=False)
    op.create_table('policy_execution_logs',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('policy_type', sa.VARCHAR(length=20), autoincrement=False, nullable=False, comment='archival or cleanup'),
    sa.Column('policy_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('dataset_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=20), autoincrement=False, nullable=False),
    sa.Column('details', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('executed_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], name=op.f('policy_execution_logs_dataset_id_fkey'), ondelete='SET NULL'),
    sa.PrimaryKeyConstraint('id', name=op.f('policy_execution_logs_pkey'))
    )
    op.create_index(op.f('ix_policy_logs_type_status'), 'policy_execution_logs', ['policy_type', 'status'], unique=False)
    op.create_index(op.f('ix_policy_logs_executed_at'), 'policy_execution_logs', ['executed_at'], unique=False)
    op.create_index(op.f('ix_policy_execution_logs_policy_id'), 'policy_execution_logs', ['policy_id'], unique=False)
    op.create_index(op.f('ix_policy_execution_logs_dataset_id'), 'policy_execution_logs', ['dataset_id'], unique=False)
    # ### end Alembic commands ###
